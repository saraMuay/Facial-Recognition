{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Facial Recognition Using CNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQLaUlqFkH_G"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from keras.utils import np_utils\n",
        "import itertools\n",
        "import warnings \n",
        "\n",
        "warnings.filterwarnings('ignore') \n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-j_3zZ_rYzR"
      },
      "source": [
        "data = np.load('ORL_faces.npz') "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wm4uLbuHl_6J"
      },
      "source": [
        "x_train = data['trainX']\n",
        "x_test = data['testX']"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVwgtNLYtbd8"
      },
      "source": [
        "# normalize every image\n",
        "x_train= np.array(x_train,dtype= 'float32')/255\n",
        "x_test = np.array(x_test,dtype='float32')/255"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clnll0hJv1qb"
      },
      "source": [
        "y_train= data['trainY']\n",
        "y_test= data['testY']"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqIOKC3K1s9P",
        "outputId": "7fe980cd-bb9c-4924-efad-461e0c9a4a28"
      },
      "source": [
        "print('x_train shape',x_train.shape )\n",
        "print('y_train shape',y_train.shape )\n",
        "print('x_test shape',x_test.shape )\n",
        "print('y_test shape',y_test.shape )"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape (240, 10304)\n",
            "y_train shape (240,)\n",
            "x_test shape (160, 10304)\n",
            "y_test shape (160,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_TA3PZW2BLj"
      },
      "source": [
        "#Split the dataset\n",
        "X_train,X_valid, Y_train, Y_valid = train_test_split(x_train, y_train, test_size= 0.05, random_state=123)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFwCPi0z7QRK",
        "outputId": "87494ec9-c952-4fe4-a1b1-12257d1cdbad"
      },
      "source": [
        "# change the images size to equal sizes\n",
        "batch_size=512\n",
        "im_shape=(112, 92, 1)\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], *im_shape)\n",
        "x_test = x_test.reshape(x_test.shape[0], *im_shape)\n",
        "X_valid = X_valid.reshape(X_valid.shape[0], *im_shape)\n",
        "\n",
        "print('x_train shape: {}'.format(y_train.shape[0]))\n",
        "print('x_test shape: {}'.format(y_test.shape))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: 240\n",
            "x_test shape: (160,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plb7jLfNHf5v"
      },
      "source": [
        "#Build a CNN model \n",
        "Model_CNN = Sequential()\n",
        "Model_CNN.add(Conv2D(filters=36, kernel_size=7, activation='relu', input_shape= im_shape))\n",
        "Model_CNN.add(MaxPooling2D(pool_size=2))\n",
        "Model_CNN.add(Conv2D(filters=54, kernel_size=5, activation='relu', input_shape= im_shape))\n",
        "Model_CNN.add(MaxPooling2D(pool_size=2))\n",
        "Model_CNN.add(Flatten())\n",
        "Model_CNN.add(Dense(2024, activation='relu'))\n",
        "Model_CNN.add(Dropout(0.5))\n",
        "Model_CNN.add(Dense(1024, activation='relu'))\n",
        "Model_CNN.add(Dropout(0.5))\n",
        "Model_CNN.add(Dense(512, activation='relu'))\n",
        "Model_CNN.add(Dropout(0.5))\n",
        "Model_CNN.add(Dense(20, activation='softmax'))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzc-71zs65z3"
      },
      "source": [
        "Model_CNN.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=Adam(lr=0.0001),\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DetdZTaDxIyQ",
        "outputId": "58766c82-f626-4b6e-89b1-75ea28ca4aa7"
      },
      "source": [
        "Model_CNN.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 106, 86, 36)       1800      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 53, 43, 36)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 49, 39, 54)        48654     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 24, 19, 54)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 24624)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2024)              49841000  \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1024)              2073600   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 20)                10260     \n",
            "=================================================================\n",
            "Total params: 52,500,114\n",
            "Trainable params: 52,500,114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E8XmgcRyQ_6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e453c215-ab0f-4e08-de1c-5bacd77e9dbf"
      },
      "source": [
        "#Train the model\n",
        "Model= Model_CNN.fit(X_train, Y_train, validation_data=(x_test, y_test), epochs=300, batch_size=32)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "8/8 [==============================] - 22s 960ms/step - loss: 3.0740 - accuracy: 0.0517 - val_loss: 2.9861 - val_accuracy: 0.0500\n",
            "Epoch 2/300\n",
            "8/8 [==============================] - 7s 886ms/step - loss: 3.0277 - accuracy: 0.0405 - val_loss: 2.9832 - val_accuracy: 0.0500\n",
            "Epoch 3/300\n",
            "8/8 [==============================] - 7s 881ms/step - loss: 3.0342 - accuracy: 0.0437 - val_loss: 2.9826 - val_accuracy: 0.0500\n",
            "Epoch 4/300\n",
            "8/8 [==============================] - 7s 885ms/step - loss: 2.9933 - accuracy: 0.0579 - val_loss: 2.9803 - val_accuracy: 0.0500\n",
            "Epoch 5/300\n",
            "8/8 [==============================] - 7s 881ms/step - loss: 2.9825 - accuracy: 0.0687 - val_loss: 2.9741 - val_accuracy: 0.1000\n",
            "Epoch 6/300\n",
            "8/8 [==============================] - 7s 879ms/step - loss: 2.9781 - accuracy: 0.0668 - val_loss: 2.9673 - val_accuracy: 0.1625\n",
            "Epoch 7/300\n",
            "8/8 [==============================] - 7s 881ms/step - loss: 2.9668 - accuracy: 0.1343 - val_loss: 2.9571 - val_accuracy: 0.0938\n",
            "Epoch 8/300\n",
            "8/8 [==============================] - 7s 872ms/step - loss: 2.9456 - accuracy: 0.1165 - val_loss: 2.9418 - val_accuracy: 0.1500\n",
            "Epoch 9/300\n",
            "8/8 [==============================] - 7s 879ms/step - loss: 2.9266 - accuracy: 0.1730 - val_loss: 2.9256 - val_accuracy: 0.1500\n",
            "Epoch 10/300\n",
            "8/8 [==============================] - 7s 884ms/step - loss: 2.9178 - accuracy: 0.1164 - val_loss: 2.9063 - val_accuracy: 0.1187\n",
            "Epoch 11/300\n",
            "8/8 [==============================] - 7s 882ms/step - loss: 2.9071 - accuracy: 0.1281 - val_loss: 2.8607 - val_accuracy: 0.1312\n",
            "Epoch 12/300\n",
            "8/8 [==============================] - 7s 885ms/step - loss: 2.8761 - accuracy: 0.1086 - val_loss: 2.8060 - val_accuracy: 0.3688\n",
            "Epoch 13/300\n",
            "8/8 [==============================] - 7s 887ms/step - loss: 2.8268 - accuracy: 0.1656 - val_loss: 2.7054 - val_accuracy: 0.3000\n",
            "Epoch 14/300\n",
            "8/8 [==============================] - 7s 879ms/step - loss: 2.7605 - accuracy: 0.1453 - val_loss: 2.6213 - val_accuracy: 0.3125\n",
            "Epoch 15/300\n",
            "8/8 [==============================] - 7s 888ms/step - loss: 2.6780 - accuracy: 0.2305 - val_loss: 2.4576 - val_accuracy: 0.3688\n",
            "Epoch 16/300\n",
            "8/8 [==============================] - 7s 894ms/step - loss: 2.4224 - accuracy: 0.2723 - val_loss: 2.2994 - val_accuracy: 0.5063\n",
            "Epoch 17/300\n",
            "8/8 [==============================] - 7s 877ms/step - loss: 2.4165 - accuracy: 0.2700 - val_loss: 2.0851 - val_accuracy: 0.5188\n",
            "Epoch 18/300\n",
            "8/8 [==============================] - 7s 884ms/step - loss: 2.2901 - accuracy: 0.3331 - val_loss: 1.9191 - val_accuracy: 0.5875\n",
            "Epoch 19/300\n",
            "8/8 [==============================] - 7s 890ms/step - loss: 2.0786 - accuracy: 0.3743 - val_loss: 1.7742 - val_accuracy: 0.6250\n",
            "Epoch 20/300\n",
            "8/8 [==============================] - 7s 890ms/step - loss: 1.9382 - accuracy: 0.4005 - val_loss: 1.5752 - val_accuracy: 0.6375\n",
            "Epoch 21/300\n",
            "8/8 [==============================] - 7s 879ms/step - loss: 1.7719 - accuracy: 0.4532 - val_loss: 1.4486 - val_accuracy: 0.6687\n",
            "Epoch 22/300\n",
            "8/8 [==============================] - 7s 878ms/step - loss: 1.6458 - accuracy: 0.5163 - val_loss: 1.3113 - val_accuracy: 0.7000\n",
            "Epoch 23/300\n",
            "8/8 [==============================] - 7s 878ms/step - loss: 1.3932 - accuracy: 0.5838 - val_loss: 1.1926 - val_accuracy: 0.7563\n",
            "Epoch 24/300\n",
            "8/8 [==============================] - 7s 888ms/step - loss: 1.4130 - accuracy: 0.5683 - val_loss: 1.1887 - val_accuracy: 0.6562\n",
            "Epoch 25/300\n",
            "8/8 [==============================] - 7s 891ms/step - loss: 1.2416 - accuracy: 0.6172 - val_loss: 1.0297 - val_accuracy: 0.6812\n",
            "Epoch 26/300\n",
            "8/8 [==============================] - 7s 886ms/step - loss: 1.0641 - accuracy: 0.7064 - val_loss: 0.9082 - val_accuracy: 0.7875\n",
            "Epoch 27/300\n",
            "8/8 [==============================] - 7s 885ms/step - loss: 0.9851 - accuracy: 0.7337 - val_loss: 0.8073 - val_accuracy: 0.8125\n",
            "Epoch 28/300\n",
            "8/8 [==============================] - 7s 880ms/step - loss: 0.8496 - accuracy: 0.7428 - val_loss: 0.7781 - val_accuracy: 0.8250\n",
            "Epoch 29/300\n",
            "8/8 [==============================] - 7s 881ms/step - loss: 0.7341 - accuracy: 0.8223 - val_loss: 0.7242 - val_accuracy: 0.8125\n",
            "Epoch 30/300\n",
            "8/8 [==============================] - 7s 891ms/step - loss: 0.6555 - accuracy: 0.7911 - val_loss: 0.6509 - val_accuracy: 0.8687\n",
            "Epoch 31/300\n",
            "8/8 [==============================] - 7s 894ms/step - loss: 0.7475 - accuracy: 0.7625 - val_loss: 0.7274 - val_accuracy: 0.8438\n",
            "Epoch 32/300\n",
            "8/8 [==============================] - 7s 889ms/step - loss: 0.7220 - accuracy: 0.7612 - val_loss: 0.5736 - val_accuracy: 0.9062\n",
            "Epoch 33/300\n",
            "8/8 [==============================] - 7s 889ms/step - loss: 0.6065 - accuracy: 0.7934 - val_loss: 0.6021 - val_accuracy: 0.8438\n",
            "Epoch 34/300\n",
            "8/8 [==============================] - 7s 897ms/step - loss: 0.5261 - accuracy: 0.8335 - val_loss: 0.4564 - val_accuracy: 0.9312\n",
            "Epoch 35/300\n",
            "8/8 [==============================] - 7s 891ms/step - loss: 0.4030 - accuracy: 0.8707 - val_loss: 0.5044 - val_accuracy: 0.8687\n",
            "Epoch 36/300\n",
            "8/8 [==============================] - 7s 899ms/step - loss: 0.3990 - accuracy: 0.8982 - val_loss: 0.4246 - val_accuracy: 0.9250\n",
            "Epoch 37/300\n",
            "8/8 [==============================] - 7s 891ms/step - loss: 0.3870 - accuracy: 0.8873 - val_loss: 0.4624 - val_accuracy: 0.9000\n",
            "Epoch 38/300\n",
            "8/8 [==============================] - 7s 879ms/step - loss: 0.3347 - accuracy: 0.9055 - val_loss: 0.4305 - val_accuracy: 0.8938\n",
            "Epoch 39/300\n",
            "8/8 [==============================] - 7s 890ms/step - loss: 0.2642 - accuracy: 0.9220 - val_loss: 0.3850 - val_accuracy: 0.9375\n",
            "Epoch 40/300\n",
            "8/8 [==============================] - 7s 889ms/step - loss: 0.2475 - accuracy: 0.9179 - val_loss: 0.3551 - val_accuracy: 0.9375\n",
            "Epoch 41/300\n",
            "8/8 [==============================] - 7s 887ms/step - loss: 0.2637 - accuracy: 0.9239 - val_loss: 0.4105 - val_accuracy: 0.9125\n",
            "Epoch 42/300\n",
            "8/8 [==============================] - 7s 897ms/step - loss: 0.2214 - accuracy: 0.9468 - val_loss: 0.3762 - val_accuracy: 0.9375\n",
            "Epoch 43/300\n",
            "8/8 [==============================] - 7s 884ms/step - loss: 0.1514 - accuracy: 0.9721 - val_loss: 0.3294 - val_accuracy: 0.9312\n",
            "Epoch 44/300\n",
            "8/8 [==============================] - 7s 884ms/step - loss: 0.1767 - accuracy: 0.9362 - val_loss: 0.3099 - val_accuracy: 0.9375\n",
            "Epoch 45/300\n",
            "8/8 [==============================] - 7s 889ms/step - loss: 0.1743 - accuracy: 0.9457 - val_loss: 0.3112 - val_accuracy: 0.9250\n",
            "Epoch 46/300\n",
            "8/8 [==============================] - 7s 886ms/step - loss: 0.1412 - accuracy: 0.9841 - val_loss: 0.4039 - val_accuracy: 0.9062\n",
            "Epoch 47/300\n",
            "8/8 [==============================] - 7s 890ms/step - loss: 0.1460 - accuracy: 0.9493 - val_loss: 0.3590 - val_accuracy: 0.9438\n",
            "Epoch 48/300\n",
            "8/8 [==============================] - 7s 894ms/step - loss: 0.1586 - accuracy: 0.9549 - val_loss: 0.3387 - val_accuracy: 0.9312\n",
            "Epoch 49/300\n",
            "8/8 [==============================] - 7s 885ms/step - loss: 0.2121 - accuracy: 0.9429 - val_loss: 0.3406 - val_accuracy: 0.9438\n",
            "Epoch 50/300\n",
            "8/8 [==============================] - 7s 885ms/step - loss: 0.1804 - accuracy: 0.9550 - val_loss: 0.3867 - val_accuracy: 0.9375\n",
            "Epoch 51/300\n",
            "8/8 [==============================] - 7s 890ms/step - loss: 0.1102 - accuracy: 0.9865 - val_loss: 0.3776 - val_accuracy: 0.9375\n",
            "Epoch 52/300\n",
            "8/8 [==============================] - 7s 890ms/step - loss: 0.0977 - accuracy: 0.9887 - val_loss: 0.4047 - val_accuracy: 0.9187\n",
            "Epoch 53/300\n",
            "8/8 [==============================] - 7s 893ms/step - loss: 0.1493 - accuracy: 0.9474 - val_loss: 0.3678 - val_accuracy: 0.9250\n",
            "Epoch 54/300\n",
            "8/8 [==============================] - 7s 884ms/step - loss: 0.1236 - accuracy: 0.9652 - val_loss: 0.3333 - val_accuracy: 0.9375\n",
            "Epoch 55/300\n",
            "8/8 [==============================] - 7s 888ms/step - loss: 0.0963 - accuracy: 0.9840 - val_loss: 0.3235 - val_accuracy: 0.9500\n",
            "Epoch 56/300\n",
            "8/8 [==============================] - 7s 893ms/step - loss: 0.0952 - accuracy: 0.9764 - val_loss: 0.3025 - val_accuracy: 0.9563\n",
            "Epoch 57/300\n",
            "8/8 [==============================] - 7s 890ms/step - loss: 0.0746 - accuracy: 0.9852 - val_loss: 0.3086 - val_accuracy: 0.9625\n",
            "Epoch 58/300\n",
            "8/8 [==============================] - 7s 879ms/step - loss: 0.0529 - accuracy: 0.9939 - val_loss: 0.3165 - val_accuracy: 0.9625\n",
            "Epoch 59/300\n",
            "8/8 [==============================] - 7s 876ms/step - loss: 0.0571 - accuracy: 0.9839 - val_loss: 0.3446 - val_accuracy: 0.9625\n",
            "Epoch 60/300\n",
            "8/8 [==============================] - 7s 894ms/step - loss: 0.0403 - accuracy: 0.9858 - val_loss: 0.3408 - val_accuracy: 0.9625\n",
            "Epoch 61/300\n",
            "8/8 [==============================] - 7s 886ms/step - loss: 0.0534 - accuracy: 0.9897 - val_loss: 0.3234 - val_accuracy: 0.9500\n",
            "Epoch 62/300\n",
            "8/8 [==============================] - 7s 879ms/step - loss: 0.0633 - accuracy: 0.9789 - val_loss: 0.3328 - val_accuracy: 0.9375\n",
            "Epoch 63/300\n",
            "8/8 [==============================] - 7s 884ms/step - loss: 0.0791 - accuracy: 0.9834 - val_loss: 0.3358 - val_accuracy: 0.9500\n",
            "Epoch 64/300\n",
            "8/8 [==============================] - 7s 891ms/step - loss: 0.0765 - accuracy: 0.9787 - val_loss: 0.3073 - val_accuracy: 0.9625\n",
            "Epoch 65/300\n",
            "8/8 [==============================] - 7s 889ms/step - loss: 0.0413 - accuracy: 0.9928 - val_loss: 0.3045 - val_accuracy: 0.9563\n",
            "Epoch 66/300\n",
            "8/8 [==============================] - 7s 888ms/step - loss: 0.0710 - accuracy: 0.9795 - val_loss: 0.3401 - val_accuracy: 0.9438\n",
            "Epoch 67/300\n",
            "8/8 [==============================] - 7s 897ms/step - loss: 0.0607 - accuracy: 0.9838 - val_loss: 0.2910 - val_accuracy: 0.9625\n",
            "Epoch 68/300\n",
            "8/8 [==============================] - 7s 886ms/step - loss: 0.0329 - accuracy: 0.9985 - val_loss: 0.3149 - val_accuracy: 0.9563\n",
            "Epoch 69/300\n",
            "8/8 [==============================] - 7s 889ms/step - loss: 0.0583 - accuracy: 0.9742 - val_loss: 0.3473 - val_accuracy: 0.9500\n",
            "Epoch 70/300\n",
            "8/8 [==============================] - 7s 913ms/step - loss: 0.0356 - accuracy: 0.9952 - val_loss: 0.3478 - val_accuracy: 0.9500\n",
            "Epoch 71/300\n",
            "8/8 [==============================] - 7s 901ms/step - loss: 0.0414 - accuracy: 0.9880 - val_loss: 0.3521 - val_accuracy: 0.9438\n",
            "Epoch 72/300\n",
            "8/8 [==============================] - 7s 892ms/step - loss: 0.0402 - accuracy: 0.9932 - val_loss: 0.3428 - val_accuracy: 0.9438\n",
            "Epoch 73/300\n",
            "8/8 [==============================] - 7s 879ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.3190 - val_accuracy: 0.9500\n",
            "Epoch 74/300\n",
            "8/8 [==============================] - 7s 883ms/step - loss: 0.0428 - accuracy: 0.9825 - val_loss: 0.2937 - val_accuracy: 0.9500\n",
            "Epoch 75/300\n",
            "8/8 [==============================] - 7s 893ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.2938 - val_accuracy: 0.9438\n",
            "Epoch 76/300\n",
            "8/8 [==============================] - 7s 887ms/step - loss: 0.0717 - accuracy: 0.9795 - val_loss: 0.3328 - val_accuracy: 0.9500\n",
            "Epoch 77/300\n",
            "8/8 [==============================] - 7s 884ms/step - loss: 0.0329 - accuracy: 0.9935 - val_loss: 0.3443 - val_accuracy: 0.9563\n",
            "Epoch 78/300\n",
            "8/8 [==============================] - 7s 891ms/step - loss: 0.0342 - accuracy: 0.9952 - val_loss: 0.3472 - val_accuracy: 0.9563\n",
            "Epoch 79/300\n",
            "8/8 [==============================] - 7s 886ms/step - loss: 0.0178 - accuracy: 0.9980 - val_loss: 0.3582 - val_accuracy: 0.9438\n",
            "Epoch 80/300\n",
            "8/8 [==============================] - 7s 893ms/step - loss: 0.0187 - accuracy: 0.9965 - val_loss: 0.3620 - val_accuracy: 0.9375\n",
            "Epoch 81/300\n",
            "8/8 [==============================] - 7s 891ms/step - loss: 0.0285 - accuracy: 0.9943 - val_loss: 0.3659 - val_accuracy: 0.9500\n",
            "Epoch 82/300\n",
            "8/8 [==============================] - 7s 892ms/step - loss: 0.0297 - accuracy: 0.9917 - val_loss: 0.3577 - val_accuracy: 0.9563\n",
            "Epoch 83/300\n",
            "8/8 [==============================] - 7s 884ms/step - loss: 0.0385 - accuracy: 0.9887 - val_loss: 0.3629 - val_accuracy: 0.9500\n",
            "Epoch 84/300\n",
            "8/8 [==============================] - 7s 879ms/step - loss: 0.0369 - accuracy: 0.9870 - val_loss: 0.3381 - val_accuracy: 0.9500\n",
            "Epoch 85/300\n",
            "8/8 [==============================] - 7s 886ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.3335 - val_accuracy: 0.9625\n",
            "Epoch 86/300\n",
            "8/8 [==============================] - 7s 894ms/step - loss: 0.0452 - accuracy: 0.9935 - val_loss: 0.3272 - val_accuracy: 0.9625\n",
            "Epoch 87/300\n",
            "8/8 [==============================] - 7s 893ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.3230 - val_accuracy: 0.9563\n",
            "Epoch 88/300\n",
            "8/8 [==============================] - 7s 885ms/step - loss: 0.0187 - accuracy: 0.9928 - val_loss: 0.3103 - val_accuracy: 0.9563\n",
            "Epoch 89/300\n",
            "8/8 [==============================] - 7s 888ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.3154 - val_accuracy: 0.9625\n",
            "Epoch 90/300\n",
            "8/8 [==============================] - 7s 887ms/step - loss: 0.0168 - accuracy: 0.9973 - val_loss: 0.3186 - val_accuracy: 0.9625\n",
            "Epoch 91/300\n",
            "8/8 [==============================] - 7s 889ms/step - loss: 0.0193 - accuracy: 0.9964 - val_loss: 0.3134 - val_accuracy: 0.9625\n",
            "Epoch 92/300\n",
            "8/8 [==============================] - 7s 894ms/step - loss: 0.0134 - accuracy: 0.9973 - val_loss: 0.3140 - val_accuracy: 0.9563\n",
            "Epoch 93/300\n",
            "8/8 [==============================] - 7s 888ms/step - loss: 0.0172 - accuracy: 0.9952 - val_loss: 0.2924 - val_accuracy: 0.9563\n",
            "Epoch 94/300\n",
            "8/8 [==============================] - 7s 887ms/step - loss: 0.0352 - accuracy: 0.9935 - val_loss: 0.2915 - val_accuracy: 0.9625\n",
            "Epoch 95/300\n",
            "8/8 [==============================] - 7s 890ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.3043 - val_accuracy: 0.9563\n",
            "Epoch 96/300\n",
            "8/8 [==============================] - 7s 890ms/step - loss: 0.0115 - accuracy: 0.9971 - val_loss: 0.4975 - val_accuracy: 0.9312\n",
            "Epoch 97/300\n",
            "8/8 [==============================] - 7s 883ms/step - loss: 0.0582 - accuracy: 0.9864 - val_loss: 0.3617 - val_accuracy: 0.9375\n",
            "Epoch 98/300\n",
            "8/8 [==============================] - 7s 893ms/step - loss: 0.0186 - accuracy: 0.9965 - val_loss: 0.4049 - val_accuracy: 0.9375\n",
            "Epoch 99/300\n",
            "8/8 [==============================] - 7s 881ms/step - loss: 0.0213 - accuracy: 0.9973 - val_loss: 0.3884 - val_accuracy: 0.9500\n",
            "Epoch 100/300\n",
            "8/8 [==============================] - 7s 888ms/step - loss: 0.0245 - accuracy: 0.9932 - val_loss: 0.3883 - val_accuracy: 0.9500\n",
            "Epoch 101/300\n",
            "8/8 [==============================] - 7s 887ms/step - loss: 0.0136 - accuracy: 0.9964 - val_loss: 0.3489 - val_accuracy: 0.9625\n",
            "Epoch 102/300\n",
            "8/8 [==============================] - 7s 885ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.3441 - val_accuracy: 0.9625\n",
            "Epoch 103/300\n",
            "8/8 [==============================] - 7s 889ms/step - loss: 0.0343 - accuracy: 0.9900 - val_loss: 0.3535 - val_accuracy: 0.9563\n",
            "Epoch 104/300\n",
            "8/8 [==============================] - 7s 890ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.3559 - val_accuracy: 0.9625\n",
            "Epoch 105/300\n",
            "8/8 [==============================] - 7s 882ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.3791 - val_accuracy: 0.9563\n",
            "Epoch 106/300\n",
            "8/8 [==============================] - 7s 887ms/step - loss: 0.0202 - accuracy: 0.9932 - val_loss: 0.3986 - val_accuracy: 0.9563\n",
            "Epoch 107/300\n",
            "8/8 [==============================] - 7s 893ms/step - loss: 0.0268 - accuracy: 0.9949 - val_loss: 0.3922 - val_accuracy: 0.9563\n",
            "Epoch 108/300\n",
            "8/8 [==============================] - 7s 887ms/step - loss: 0.0131 - accuracy: 0.9952 - val_loss: 0.3852 - val_accuracy: 0.9625\n",
            "Epoch 109/300\n",
            "8/8 [==============================] - 7s 885ms/step - loss: 0.0204 - accuracy: 0.9980 - val_loss: 0.3726 - val_accuracy: 0.9500\n",
            "Epoch 110/300\n",
            "8/8 [==============================] - 7s 891ms/step - loss: 0.0206 - accuracy: 0.9965 - val_loss: 0.3844 - val_accuracy: 0.9438\n",
            "Epoch 111/300\n",
            "8/8 [==============================] - 7s 892ms/step - loss: 0.0198 - accuracy: 0.9935 - val_loss: 0.6001 - val_accuracy: 0.9000\n",
            "Epoch 112/300\n",
            "8/8 [==============================] - 7s 879ms/step - loss: 0.0619 - accuracy: 0.9743 - val_loss: 0.3763 - val_accuracy: 0.9438\n",
            "Epoch 113/300\n",
            "8/8 [==============================] - 7s 884ms/step - loss: 0.0193 - accuracy: 0.9935 - val_loss: 0.3736 - val_accuracy: 0.9438\n",
            "Epoch 114/300\n",
            "8/8 [==============================] - 7s 885ms/step - loss: 0.0295 - accuracy: 0.9880 - val_loss: 0.3309 - val_accuracy: 0.9563\n",
            "Epoch 115/300\n",
            "8/8 [==============================] - 7s 884ms/step - loss: 0.0265 - accuracy: 0.9900 - val_loss: 0.4162 - val_accuracy: 0.9312\n",
            "Epoch 116/300\n",
            "8/8 [==============================] - 7s 883ms/step - loss: 0.0254 - accuracy: 0.9900 - val_loss: 0.3230 - val_accuracy: 0.9625\n",
            "Epoch 117/300\n",
            "8/8 [==============================] - 7s 886ms/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 0.3355 - val_accuracy: 0.9625\n",
            "Epoch 118/300\n",
            "8/8 [==============================] - 7s 891ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.3726 - val_accuracy: 0.9500\n",
            "Epoch 119/300\n",
            "8/8 [==============================] - 7s 889ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.3661 - val_accuracy: 0.9500\n",
            "Epoch 120/300\n",
            "8/8 [==============================] - 7s 885ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.3596 - val_accuracy: 0.9563\n",
            "Epoch 121/300\n",
            "8/8 [==============================] - 7s 890ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.3629 - val_accuracy: 0.9625\n",
            "Epoch 122/300\n",
            "8/8 [==============================] - 7s 892ms/step - loss: 0.0226 - accuracy: 0.9900 - val_loss: 0.3967 - val_accuracy: 0.9625\n",
            "Epoch 123/300\n",
            "8/8 [==============================] - 7s 884ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.3835 - val_accuracy: 0.9625\n",
            "Epoch 124/300\n",
            "8/8 [==============================] - 7s 889ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.3802 - val_accuracy: 0.9625\n",
            "Epoch 125/300\n",
            "8/8 [==============================] - 7s 891ms/step - loss: 0.0092 - accuracy: 0.9985 - val_loss: 0.3768 - val_accuracy: 0.9625\n",
            "Epoch 126/300\n",
            "8/8 [==============================] - 7s 890ms/step - loss: 0.0109 - accuracy: 0.9964 - val_loss: 0.4010 - val_accuracy: 0.9500\n",
            "Epoch 127/300\n",
            "8/8 [==============================] - 7s 886ms/step - loss: 0.0204 - accuracy: 0.9900 - val_loss: 0.3753 - val_accuracy: 0.9625\n",
            "Epoch 128/300\n",
            "8/8 [==============================] - 7s 884ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3863 - val_accuracy: 0.9563\n",
            "Epoch 129/300\n",
            "8/8 [==============================] - 7s 890ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.3947 - val_accuracy: 0.9563\n",
            "Epoch 130/300\n",
            "8/8 [==============================] - 7s 894ms/step - loss: 0.0104 - accuracy: 0.9990 - val_loss: 0.3967 - val_accuracy: 0.9625\n",
            "Epoch 131/300\n",
            "8/8 [==============================] - 7s 893ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.3798 - val_accuracy: 0.9312\n",
            "Epoch 132/300\n",
            "8/8 [==============================] - 7s 884ms/step - loss: 0.0374 - accuracy: 0.9832 - val_loss: 0.3613 - val_accuracy: 0.9625\n",
            "Epoch 133/300\n",
            "8/8 [==============================] - 7s 888ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.3812 - val_accuracy: 0.9500\n",
            "Epoch 134/300\n",
            "8/8 [==============================] - 7s 890ms/step - loss: 0.0188 - accuracy: 0.9964 - val_loss: 0.3584 - val_accuracy: 0.9625\n",
            "Epoch 135/300\n",
            "8/8 [==============================] - 7s 892ms/step - loss: 0.0103 - accuracy: 0.9973 - val_loss: 0.3492 - val_accuracy: 0.9625\n",
            "Epoch 136/300\n",
            "8/8 [==============================] - 7s 888ms/step - loss: 0.0128 - accuracy: 0.9964 - val_loss: 0.3705 - val_accuracy: 0.9625\n",
            "Epoch 137/300\n",
            "8/8 [==============================] - 7s 889ms/step - loss: 0.0144 - accuracy: 0.9886 - val_loss: 0.3823 - val_accuracy: 0.9563\n",
            "Epoch 138/300\n",
            "8/8 [==============================] - 7s 890ms/step - loss: 0.0226 - accuracy: 0.9961 - val_loss: 0.3440 - val_accuracy: 0.9625\n",
            "Epoch 139/300\n",
            "8/8 [==============================] - 7s 889ms/step - loss: 0.0219 - accuracy: 0.9973 - val_loss: 0.3158 - val_accuracy: 0.9500\n",
            "Epoch 140/300\n",
            "8/8 [==============================] - 7s 887ms/step - loss: 0.0446 - accuracy: 0.9855 - val_loss: 0.3009 - val_accuracy: 0.9563\n",
            "Epoch 141/300\n",
            "8/8 [==============================] - 7s 890ms/step - loss: 0.0316 - accuracy: 0.9900 - val_loss: 0.2657 - val_accuracy: 0.9563\n",
            "Epoch 142/300\n",
            "8/8 [==============================] - 7s 887ms/step - loss: 0.0294 - accuracy: 0.9959 - val_loss: 0.2755 - val_accuracy: 0.9563\n",
            "Epoch 143/300\n",
            "8/8 [==============================] - 7s 889ms/step - loss: 0.0626 - accuracy: 0.9787 - val_loss: 0.3263 - val_accuracy: 0.9500\n",
            "Epoch 144/300\n",
            "8/8 [==============================] - 7s 886ms/step - loss: 0.0390 - accuracy: 0.9743 - val_loss: 0.3432 - val_accuracy: 0.9625\n",
            "Epoch 145/300\n",
            "8/8 [==============================] - 7s 890ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.3718 - val_accuracy: 0.9625\n",
            "Epoch 146/300\n",
            "8/8 [==============================] - 7s 890ms/step - loss: 0.0177 - accuracy: 0.9959 - val_loss: 0.4062 - val_accuracy: 0.9500\n",
            "Epoch 147/300\n",
            "8/8 [==============================] - 7s 889ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.4192 - val_accuracy: 0.9438\n",
            "Epoch 148/300\n",
            "8/8 [==============================] - 7s 883ms/step - loss: 0.0140 - accuracy: 0.9905 - val_loss: 0.3898 - val_accuracy: 0.9625\n",
            "Epoch 149/300\n",
            "8/8 [==============================] - 7s 890ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.3807 - val_accuracy: 0.9625\n",
            "Epoch 150/300\n",
            "8/8 [==============================] - 7s 890ms/step - loss: 0.0101 - accuracy: 0.9952 - val_loss: 0.3687 - val_accuracy: 0.9625\n",
            "Epoch 151/300\n",
            "8/8 [==============================] - 7s 894ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.3656 - val_accuracy: 0.9625\n",
            "Epoch 152/300\n",
            "8/8 [==============================] - 7s 889ms/step - loss: 0.0161 - accuracy: 0.9952 - val_loss: 0.3391 - val_accuracy: 0.9563\n",
            "Epoch 153/300\n",
            "8/8 [==============================] - 7s 891ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.3371 - val_accuracy: 0.9500\n",
            "Epoch 154/300\n",
            "8/8 [==============================] - 7s 893ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.3552 - val_accuracy: 0.9563\n",
            "Epoch 155/300\n",
            "8/8 [==============================] - 7s 895ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.3802 - val_accuracy: 0.9625\n",
            "Epoch 156/300\n",
            "8/8 [==============================] - 7s 889ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.3944 - val_accuracy: 0.9625\n",
            "Epoch 157/300\n",
            "8/8 [==============================] - 7s 888ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.4022 - val_accuracy: 0.9563\n",
            "Epoch 158/300\n",
            "8/8 [==============================] - 7s 895ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4060 - val_accuracy: 0.9563\n",
            "Epoch 159/300\n",
            "8/8 [==============================] - 7s 890ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.4023 - val_accuracy: 0.9625\n",
            "Epoch 160/300\n",
            "8/8 [==============================] - 7s 892ms/step - loss: 0.0106 - accuracy: 0.9900 - val_loss: 0.4156 - val_accuracy: 0.9625\n",
            "Epoch 161/300\n",
            "8/8 [==============================] - 7s 899ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.4172 - val_accuracy: 0.9625\n",
            "Epoch 162/300\n",
            "8/8 [==============================] - 7s 885ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4144 - val_accuracy: 0.9625\n",
            "Epoch 163/300\n",
            "8/8 [==============================] - 7s 885ms/step - loss: 0.0064 - accuracy: 0.9973 - val_loss: 0.3919 - val_accuracy: 0.9625\n",
            "Epoch 164/300\n",
            "8/8 [==============================] - 7s 892ms/step - loss: 0.0184 - accuracy: 0.9900 - val_loss: 0.3959 - val_accuracy: 0.9625\n",
            "Epoch 165/300\n",
            "8/8 [==============================] - 7s 887ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4091 - val_accuracy: 0.9625\n",
            "Epoch 166/300\n",
            "8/8 [==============================] - 7s 889ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.4199 - val_accuracy: 0.9625\n",
            "Epoch 167/300\n",
            "8/8 [==============================] - 7s 893ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4282 - val_accuracy: 0.9625\n",
            "Epoch 168/300\n",
            "8/8 [==============================] - 7s 888ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4300 - val_accuracy: 0.9625\n",
            "Epoch 169/300\n",
            "8/8 [==============================] - 7s 885ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.4263 - val_accuracy: 0.9625\n",
            "Epoch 170/300\n",
            "8/8 [==============================] - 7s 890ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4206 - val_accuracy: 0.9625\n",
            "Epoch 171/300\n",
            "8/8 [==============================] - 7s 892ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4180 - val_accuracy: 0.9625\n",
            "Epoch 172/300\n",
            "8/8 [==============================] - 7s 894ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.4242 - val_accuracy: 0.9625\n",
            "Epoch 173/300\n",
            "8/8 [==============================] - 7s 888ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.4274 - val_accuracy: 0.9500\n",
            "Epoch 174/300\n",
            "8/8 [==============================] - 7s 895ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.4567 - val_accuracy: 0.9375\n",
            "Epoch 175/300\n",
            "8/8 [==============================] - 7s 896ms/step - loss: 0.0067 - accuracy: 0.9952 - val_loss: 0.4652 - val_accuracy: 0.9438\n",
            "Epoch 176/300\n",
            "8/8 [==============================] - 7s 892ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4636 - val_accuracy: 0.9500\n",
            "Epoch 177/300\n",
            "8/8 [==============================] - 7s 888ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.4488 - val_accuracy: 0.9563\n",
            "Epoch 178/300\n",
            "8/8 [==============================] - 7s 890ms/step - loss: 0.0089 - accuracy: 0.9900 - val_loss: 0.5104 - val_accuracy: 0.9187\n",
            "Epoch 179/300\n",
            "8/8 [==============================] - 7s 888ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.4761 - val_accuracy: 0.9375\n",
            "Epoch 180/300\n",
            "8/8 [==============================] - 7s 893ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.4376 - val_accuracy: 0.9563\n",
            "Epoch 181/300\n",
            "8/8 [==============================] - 7s 884ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.4331 - val_accuracy: 0.9625\n",
            "Epoch 182/300\n",
            "8/8 [==============================] - 7s 895ms/step - loss: 0.0073 - accuracy: 0.9964 - val_loss: 0.4231 - val_accuracy: 0.9625\n",
            "Epoch 183/300\n",
            "8/8 [==============================] - 7s 888ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.4118 - val_accuracy: 0.9625\n",
            "Epoch 184/300\n",
            "8/8 [==============================] - 7s 888ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.4126 - val_accuracy: 0.9625\n",
            "Epoch 185/300\n",
            "8/8 [==============================] - 7s 881ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.4157 - val_accuracy: 0.9625\n",
            "Epoch 186/300\n",
            "8/8 [==============================] - 7s 894ms/step - loss: 8.6034e-04 - accuracy: 1.0000 - val_loss: 0.4176 - val_accuracy: 0.9625\n",
            "Epoch 187/300\n",
            "8/8 [==============================] - 7s 883ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.4118 - val_accuracy: 0.9625\n",
            "Epoch 188/300\n",
            "8/8 [==============================] - 7s 890ms/step - loss: 0.0122 - accuracy: 0.9935 - val_loss: 0.3788 - val_accuracy: 0.9438\n",
            "Epoch 189/300\n",
            "8/8 [==============================] - 7s 887ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.3727 - val_accuracy: 0.9438\n",
            "Epoch 190/300\n",
            "8/8 [==============================] - 7s 884ms/step - loss: 0.0110 - accuracy: 0.9900 - val_loss: 0.3384 - val_accuracy: 0.9625\n",
            "Epoch 191/300\n",
            "8/8 [==============================] - 7s 885ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.3493 - val_accuracy: 0.9563\n",
            "Epoch 192/300\n",
            "8/8 [==============================] - 7s 889ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.3517 - val_accuracy: 0.9563\n",
            "Epoch 193/300\n",
            "8/8 [==============================] - 7s 884ms/step - loss: 0.0082 - accuracy: 0.9935 - val_loss: 0.3383 - val_accuracy: 0.9625\n",
            "Epoch 194/300\n",
            "8/8 [==============================] - 7s 899ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.3419 - val_accuracy: 0.9625\n",
            "Epoch 195/300\n",
            "8/8 [==============================] - 7s 887ms/step - loss: 0.0060 - accuracy: 0.9973 - val_loss: 0.3610 - val_accuracy: 0.9563\n",
            "Epoch 196/300\n",
            "8/8 [==============================] - 7s 885ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.3718 - val_accuracy: 0.9563\n",
            "Epoch 197/300\n",
            "8/8 [==============================] - 7s 881ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.3946 - val_accuracy: 0.9625\n",
            "Epoch 198/300\n",
            "8/8 [==============================] - 7s 889ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.4131 - val_accuracy: 0.9625\n",
            "Epoch 199/300\n",
            "8/8 [==============================] - 7s 887ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4217 - val_accuracy: 0.9625\n",
            "Epoch 200/300\n",
            "8/8 [==============================] - 7s 889ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.4118 - val_accuracy: 0.9625\n",
            "Epoch 201/300\n",
            "8/8 [==============================] - 7s 888ms/step - loss: 0.0147 - accuracy: 0.9905 - val_loss: 0.3808 - val_accuracy: 0.9625\n",
            "Epoch 202/300\n",
            "8/8 [==============================] - 7s 899ms/step - loss: 0.0036 - accuracy: 0.9985 - val_loss: 0.3726 - val_accuracy: 0.9625\n",
            "Epoch 203/300\n",
            "8/8 [==============================] - 7s 887ms/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.4175 - val_accuracy: 0.9625\n",
            "Epoch 204/300\n",
            "8/8 [==============================] - 7s 891ms/step - loss: 0.0137 - accuracy: 0.9900 - val_loss: 0.4567 - val_accuracy: 0.9500\n",
            "Epoch 205/300\n",
            "8/8 [==============================] - 7s 891ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.4509 - val_accuracy: 0.9563\n",
            "Epoch 206/300\n",
            "8/8 [==============================] - 7s 886ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.4550 - val_accuracy: 0.9563\n",
            "Epoch 207/300\n",
            "8/8 [==============================] - 7s 890ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.4553 - val_accuracy: 0.9563\n",
            "Epoch 208/300\n",
            "8/8 [==============================] - 7s 887ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.4524 - val_accuracy: 0.9625\n",
            "Epoch 209/300\n",
            "8/8 [==============================] - 7s 888ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.4427 - val_accuracy: 0.9625\n",
            "Epoch 210/300\n",
            "8/8 [==============================] - 7s 887ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.4322 - val_accuracy: 0.9563\n",
            "Epoch 211/300\n",
            "8/8 [==============================] - 7s 894ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.4378 - val_accuracy: 0.9563\n",
            "Epoch 212/300\n",
            "8/8 [==============================] - 7s 891ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.4406 - val_accuracy: 0.9563\n",
            "Epoch 213/300\n",
            "8/8 [==============================] - 7s 882ms/step - loss: 0.0040 - accuracy: 0.9964 - val_loss: 0.4271 - val_accuracy: 0.9500\n",
            "Epoch 214/300\n",
            "8/8 [==============================] - 7s 894ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4145 - val_accuracy: 0.9500\n",
            "Epoch 215/300\n",
            "8/8 [==============================] - 7s 892ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4084 - val_accuracy: 0.9500\n",
            "Epoch 216/300\n",
            "8/8 [==============================] - 7s 893ms/step - loss: 0.0254 - accuracy: 0.9900 - val_loss: 0.4237 - val_accuracy: 0.9500\n",
            "Epoch 217/300\n",
            "8/8 [==============================] - 7s 892ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.5130 - val_accuracy: 0.9312\n",
            "Epoch 218/300\n",
            "8/8 [==============================] - 7s 889ms/step - loss: 0.0382 - accuracy: 0.9873 - val_loss: 0.4833 - val_accuracy: 0.9375\n",
            "Epoch 219/300\n",
            "8/8 [==============================] - 7s 890ms/step - loss: 0.0318 - accuracy: 0.9914 - val_loss: 0.4124 - val_accuracy: 0.9500\n",
            "Epoch 220/300\n",
            "8/8 [==============================] - 7s 899ms/step - loss: 0.0119 - accuracy: 0.9935 - val_loss: 0.3718 - val_accuracy: 0.9563\n",
            "Epoch 221/300\n",
            "8/8 [==============================] - 7s 887ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.3621 - val_accuracy: 0.9438\n",
            "Epoch 222/300\n",
            "8/8 [==============================] - 7s 893ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.3729 - val_accuracy: 0.9438\n",
            "Epoch 223/300\n",
            "8/8 [==============================] - 7s 890ms/step - loss: 0.0310 - accuracy: 0.9781 - val_loss: 0.3720 - val_accuracy: 0.9500\n",
            "Epoch 224/300\n",
            "8/8 [==============================] - 7s 884ms/step - loss: 0.0141 - accuracy: 0.9964 - val_loss: 0.3456 - val_accuracy: 0.9500\n",
            "Epoch 225/300\n",
            "8/8 [==============================] - 7s 890ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.3487 - val_accuracy: 0.9563\n",
            "Epoch 226/300\n",
            "8/8 [==============================] - 7s 890ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.3588 - val_accuracy: 0.9563\n",
            "Epoch 227/300\n",
            "8/8 [==============================] - 7s 887ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.3761 - val_accuracy: 0.9625\n",
            "Epoch 228/300\n",
            "8/8 [==============================] - 7s 887ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.3682 - val_accuracy: 0.9563\n",
            "Epoch 229/300\n",
            "8/8 [==============================] - 7s 885ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.3640 - val_accuracy: 0.9563\n",
            "Epoch 230/300\n",
            "8/8 [==============================] - 7s 889ms/step - loss: 0.0078 - accuracy: 0.9973 - val_loss: 0.3448 - val_accuracy: 0.9625\n",
            "Epoch 231/300\n",
            "8/8 [==============================] - 7s 890ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.3927 - val_accuracy: 0.9187\n",
            "Epoch 232/300\n",
            "8/8 [==============================] - 7s 892ms/step - loss: 0.0250 - accuracy: 0.9835 - val_loss: 0.4039 - val_accuracy: 0.9625\n",
            "Epoch 233/300\n",
            "8/8 [==============================] - 7s 885ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4298 - val_accuracy: 0.9625\n",
            "Epoch 234/300\n",
            "8/8 [==============================] - 7s 894ms/step - loss: 0.0079 - accuracy: 0.9935 - val_loss: 0.4372 - val_accuracy: 0.9563\n",
            "Epoch 235/300\n",
            "8/8 [==============================] - 7s 884ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.4458 - val_accuracy: 0.9438\n",
            "Epoch 236/300\n",
            "8/8 [==============================] - 7s 909ms/step - loss: 0.0089 - accuracy: 0.9980 - val_loss: 0.4456 - val_accuracy: 0.9563\n",
            "Epoch 237/300\n",
            "8/8 [==============================] - 7s 893ms/step - loss: 0.0147 - accuracy: 0.9905 - val_loss: 0.4508 - val_accuracy: 0.9563\n",
            "Epoch 238/300\n",
            "8/8 [==============================] - 7s 907ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5091 - val_accuracy: 0.9187\n",
            "Epoch 239/300\n",
            "8/8 [==============================] - 7s 890ms/step - loss: 0.0099 - accuracy: 0.9973 - val_loss: 0.4176 - val_accuracy: 0.9625\n",
            "Epoch 240/300\n",
            "8/8 [==============================] - 7s 889ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.4353 - val_accuracy: 0.9500\n",
            "Epoch 241/300\n",
            "8/8 [==============================] - 7s 895ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4346 - val_accuracy: 0.9438\n",
            "Epoch 242/300\n",
            "8/8 [==============================] - 7s 900ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4249 - val_accuracy: 0.9625\n",
            "Epoch 243/300\n",
            "8/8 [==============================] - 7s 901ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4849 - val_accuracy: 0.9375\n",
            "Epoch 244/300\n",
            "8/8 [==============================] - 7s 906ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.4738 - val_accuracy: 0.9375\n",
            "Epoch 245/300\n",
            "8/8 [==============================] - 7s 897ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.4620 - val_accuracy: 0.9625\n",
            "Epoch 246/300\n",
            "8/8 [==============================] - 7s 890ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.4749 - val_accuracy: 0.9625\n",
            "Epoch 247/300\n",
            "8/8 [==============================] - 7s 894ms/step - loss: 0.0060 - accuracy: 0.9935 - val_loss: 0.5131 - val_accuracy: 0.9563\n",
            "Epoch 248/300\n",
            "8/8 [==============================] - 7s 891ms/step - loss: 0.0074 - accuracy: 0.9952 - val_loss: 0.5478 - val_accuracy: 0.9500\n",
            "Epoch 249/300\n",
            "8/8 [==============================] - 7s 892ms/step - loss: 0.0081 - accuracy: 0.9952 - val_loss: 0.5420 - val_accuracy: 0.9563\n",
            "Epoch 250/300\n",
            "8/8 [==============================] - 7s 906ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5377 - val_accuracy: 0.9625\n",
            "Epoch 251/300\n",
            "8/8 [==============================] - 7s 901ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.5239 - val_accuracy: 0.9625\n",
            "Epoch 252/300\n",
            "8/8 [==============================] - 7s 893ms/step - loss: 0.0073 - accuracy: 0.9964 - val_loss: 0.5288 - val_accuracy: 0.9625\n",
            "Epoch 253/300\n",
            "8/8 [==============================] - 7s 898ms/step - loss: 0.0045 - accuracy: 0.9980 - val_loss: 0.5344 - val_accuracy: 0.9563\n",
            "Epoch 254/300\n",
            "8/8 [==============================] - 7s 893ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5348 - val_accuracy: 0.9625\n",
            "Epoch 255/300\n",
            "8/8 [==============================] - 7s 901ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.5455 - val_accuracy: 0.9563\n",
            "Epoch 256/300\n",
            "8/8 [==============================] - 7s 893ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5521 - val_accuracy: 0.9500\n",
            "Epoch 257/300\n",
            "8/8 [==============================] - 7s 912ms/step - loss: 0.0036 - accuracy: 0.9985 - val_loss: 0.5506 - val_accuracy: 0.9500\n",
            "Epoch 258/300\n",
            "8/8 [==============================] - 7s 894ms/step - loss: 3.3325e-04 - accuracy: 1.0000 - val_loss: 0.5435 - val_accuracy: 0.9500\n",
            "Epoch 259/300\n",
            "8/8 [==============================] - 7s 900ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.5353 - val_accuracy: 0.9563\n",
            "Epoch 260/300\n",
            "8/8 [==============================] - 7s 890ms/step - loss: 6.2588e-04 - accuracy: 1.0000 - val_loss: 0.5335 - val_accuracy: 0.9625\n",
            "Epoch 261/300\n",
            "8/8 [==============================] - 7s 892ms/step - loss: 6.3464e-04 - accuracy: 1.0000 - val_loss: 0.5345 - val_accuracy: 0.9625\n",
            "Epoch 262/300\n",
            "8/8 [==============================] - 7s 894ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.5376 - val_accuracy: 0.9625\n",
            "Epoch 263/300\n",
            "8/8 [==============================] - 7s 908ms/step - loss: 3.3885e-04 - accuracy: 1.0000 - val_loss: 0.5398 - val_accuracy: 0.9625\n",
            "Epoch 264/300\n",
            "8/8 [==============================] - 7s 907ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5446 - val_accuracy: 0.9625\n",
            "Epoch 265/300\n",
            "8/8 [==============================] - 7s 887ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.5530 - val_accuracy: 0.9625\n",
            "Epoch 266/300\n",
            "8/8 [==============================] - 7s 897ms/step - loss: 0.0153 - accuracy: 0.9935 - val_loss: 0.5195 - val_accuracy: 0.9500\n",
            "Epoch 267/300\n",
            "8/8 [==============================] - 7s 890ms/step - loss: 5.6144e-04 - accuracy: 1.0000 - val_loss: 0.5313 - val_accuracy: 0.9312\n",
            "Epoch 268/300\n",
            "8/8 [==============================] - 7s 904ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.5323 - val_accuracy: 0.9312\n",
            "Epoch 269/300\n",
            "8/8 [==============================] - 7s 903ms/step - loss: 0.0236 - accuracy: 0.9908 - val_loss: 0.4967 - val_accuracy: 0.9438\n",
            "Epoch 270/300\n",
            "8/8 [==============================] - 7s 882ms/step - loss: 7.9245e-04 - accuracy: 1.0000 - val_loss: 0.4750 - val_accuracy: 0.9438\n",
            "Epoch 271/300\n",
            "8/8 [==============================] - 7s 905ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.4605 - val_accuracy: 0.9500\n",
            "Epoch 272/300\n",
            "8/8 [==============================] - 7s 892ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4538 - val_accuracy: 0.9500\n",
            "Epoch 273/300\n",
            "8/8 [==============================] - 7s 893ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.4504 - val_accuracy: 0.9563\n",
            "Epoch 274/300\n",
            "8/8 [==============================] - 7s 893ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4511 - val_accuracy: 0.9563\n",
            "Epoch 275/300\n",
            "8/8 [==============================] - 7s 895ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4569 - val_accuracy: 0.9625\n",
            "Epoch 276/300\n",
            "8/8 [==============================] - 7s 907ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4639 - val_accuracy: 0.9625\n",
            "Epoch 277/300\n",
            "8/8 [==============================] - 7s 909ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4699 - val_accuracy: 0.9625\n",
            "Epoch 278/300\n",
            "8/8 [==============================] - 7s 898ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.4791 - val_accuracy: 0.9625\n",
            "Epoch 279/300\n",
            "8/8 [==============================] - 7s 902ms/step - loss: 9.3332e-04 - accuracy: 1.0000 - val_loss: 0.4819 - val_accuracy: 0.9625\n",
            "Epoch 280/300\n",
            "8/8 [==============================] - 7s 897ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4838 - val_accuracy: 0.9625\n",
            "Epoch 281/300\n",
            "8/8 [==============================] - 7s 890ms/step - loss: 4.5920e-04 - accuracy: 1.0000 - val_loss: 0.4845 - val_accuracy: 0.9625\n",
            "Epoch 282/300\n",
            "8/8 [==============================] - 7s 892ms/step - loss: 5.5632e-04 - accuracy: 1.0000 - val_loss: 0.4861 - val_accuracy: 0.9625\n",
            "Epoch 283/300\n",
            "8/8 [==============================] - 7s 891ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4870 - val_accuracy: 0.9625\n",
            "Epoch 284/300\n",
            "8/8 [==============================] - 7s 914ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4940 - val_accuracy: 0.9625\n",
            "Epoch 285/300\n",
            "8/8 [==============================] - 7s 902ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.9625\n",
            "Epoch 286/300\n",
            "8/8 [==============================] - 7s 903ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.5072 - val_accuracy: 0.9563\n",
            "Epoch 287/300\n",
            "8/8 [==============================] - 7s 910ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5273 - val_accuracy: 0.9563\n",
            "Epoch 288/300\n",
            "8/8 [==============================] - 7s 902ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5193 - val_accuracy: 0.9625\n",
            "Epoch 289/300\n",
            "8/8 [==============================] - 7s 888ms/step - loss: 7.9501e-04 - accuracy: 1.0000 - val_loss: 0.5092 - val_accuracy: 0.9625\n",
            "Epoch 290/300\n",
            "8/8 [==============================] - 7s 897ms/step - loss: 5.7293e-04 - accuracy: 1.0000 - val_loss: 0.5065 - val_accuracy: 0.9625\n",
            "Epoch 291/300\n",
            "8/8 [==============================] - 7s 888ms/step - loss: 1.6090e-04 - accuracy: 1.0000 - val_loss: 0.5074 - val_accuracy: 0.9625\n",
            "Epoch 292/300\n",
            "8/8 [==============================] - 7s 896ms/step - loss: 4.6894e-04 - accuracy: 1.0000 - val_loss: 0.5076 - val_accuracy: 0.9625\n",
            "Epoch 293/300\n",
            "8/8 [==============================] - 7s 902ms/step - loss: 3.8408e-04 - accuracy: 1.0000 - val_loss: 0.5056 - val_accuracy: 0.9625\n",
            "Epoch 294/300\n",
            "8/8 [==============================] - 7s 898ms/step - loss: 3.0358e-04 - accuracy: 1.0000 - val_loss: 0.5052 - val_accuracy: 0.9625\n",
            "Epoch 295/300\n",
            "8/8 [==============================] - 7s 900ms/step - loss: 7.0431e-04 - accuracy: 1.0000 - val_loss: 0.5014 - val_accuracy: 0.9625\n",
            "Epoch 296/300\n",
            "8/8 [==============================] - 7s 903ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5025 - val_accuracy: 0.9625\n",
            "Epoch 297/300\n",
            "8/8 [==============================] - 7s 890ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4843 - val_accuracy: 0.9625\n",
            "Epoch 298/300\n",
            "8/8 [==============================] - 7s 889ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4653 - val_accuracy: 0.9563\n",
            "Epoch 299/300\n",
            "8/8 [==============================] - 7s 894ms/step - loss: 3.5965e-04 - accuracy: 1.0000 - val_loss: 0.4585 - val_accuracy: 0.9563\n",
            "Epoch 300/300\n",
            "8/8 [==============================] - 7s 892ms/step - loss: 8.8419e-04 - accuracy: 1.0000 - val_loss: 0.4578 - val_accuracy: 0.9563\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0s0E9D86jss",
        "outputId": "24f77ea3-efd2-4830-fdbe-6cd0b54a108d"
      },
      "source": [
        "Scores = Model_CNN.evaluate( x_test, y_test, verbose=0)\n",
        "\n",
        "print(\"Accuracy: %.2f%%\" % (Scores[1]*100))\n",
        "#print('Loss Value: '.format  Scores[0])\n",
        "\n",
        "print('Loss Value: {}'.format(np.around(Scores[0],2)))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 95.63%\n",
            "Loss Value: 0.46\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g74J8OiUOJe3",
        "outputId": "84d867a5-fec7-4026-9e19-45195a939b4a"
      },
      "source": [
        "Model.history.keys()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "kg7h8v9S6jm0",
        "outputId": "c8a3cff4-c13e-4205-c7f1-849c072616b4"
      },
      "source": [
        "# Plot the Model for Accuracy\n",
        "plt.plot(Model.history['accuracy'])\n",
        "plt.plot(Model.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "cc3CFeCo6jiX",
        "outputId": "0af120cf-cdb1-4925-bf4e-8a4e2590f314"
      },
      "source": [
        "# Plot the Model  for loss\n",
        "plt.plot(Model.history['loss'])\n",
        "plt.plot(Model.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "st7rKWPByfUY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "764a9839-96f1-4e24-91f4-73d871f7cc16"
      },
      "source": [
        "predicted = Model_CNN.predict(x_test)\n",
        "y = Model_CNN.predict_classes(x_test)\n",
        "Acc = accuracy_score(y_test, y)\n",
        "print('Accuracy: %.2f%%' % (Acc*100))\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 95.62%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZFXRz5skbs7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7649aaa7-8481-4647-86a8-ca9ef83f399b"
      },
      "source": [
        "predict_4= Model_CNN.predict(x_test[:4])\n",
        "print(predict_4)\n",
        "print( y_test[:4])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[9.88804281e-01 3.32317832e-05 5.25117343e-07 5.36152633e-08\n",
            "  8.32488567e-08 4.42473237e-07 9.55297037e-06 5.40004930e-06\n",
            "  1.50203991e-08 2.33143318e-08 5.48793139e-07 3.01247439e-07\n",
            "  1.09794337e-05 1.69505415e-06 4.28150815e-05 2.58610654e-03\n",
            "  3.12664597e-05 3.78439813e-06 8.46863911e-03 2.02231178e-07]\n",
            " [9.71035302e-01 3.77108087e-08 6.41209308e-09 2.06767270e-10\n",
            "  4.26896157e-10 9.76971490e-11 1.43160825e-08 3.40001116e-09\n",
            "  4.04437421e-12 3.13751195e-12 3.53091667e-09 1.49736099e-10\n",
            "  9.82726874e-07 1.09476677e-08 4.80402118e-09 2.89615449e-02\n",
            "  1.76104944e-08 1.76368985e-06 4.70411720e-07 4.72143658e-10]\n",
            " [9.97023046e-01 5.27244301e-05 7.38803146e-06 4.58529485e-06\n",
            "  1.74192028e-05 5.56221756e-04 1.56311889e-05 1.32085279e-05\n",
            "  1.19125453e-07 7.12273106e-07 1.76791698e-04 8.71326938e-06\n",
            "  1.17493875e-03 1.94420616e-04 1.13907583e-04 4.05479106e-04\n",
            "  7.65180266e-06 9.66747830e-05 1.27111271e-04 3.18258731e-06]\n",
            " [9.96221900e-01 1.50474416e-05 1.41388099e-07 7.03695093e-07\n",
            "  5.04231430e-08 1.17551409e-08 1.09500860e-07 1.25740291e-06\n",
            "  4.51852022e-09 1.56236393e-08 1.29976412e-08 5.10719728e-05\n",
            "  4.86048346e-04 7.94272296e-07 1.26290161e-07 2.63224374e-05\n",
            "  5.94421472e-05 2.04172484e-05 3.11651733e-03 5.44168088e-09]]\n",
            "[0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbuOtbK10hjA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ba0d211-039f-4aad-dec2-e6247a0eeddd"
      },
      "source": [
        "Matrix = confusion_matrix(y_test, y)\n",
        "Matrix"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 2, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8HGk3y62-l3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "458d21ad-740d-42c8-b593-5cc34ff6b81b"
      },
      "source": [
        "y_test1 = np_utils.to_categorical(y_test, 20)\n",
        "y_test1"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubsvr1pU6My0",
        "outputId": "e9d430ec-87f7-45f3-f5db-2a6bd2dd7f93"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape= im_shape, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(20, activation='softmax'))\n",
        "\n",
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=Adam(lr=0.0001),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_24 (Conv2D)           (None, 112, 92, 32)       320       \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 112, 92, 32)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 112, 92, 32)       9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 56, 46, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 56, 46, 64)        18496     \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 56, 46, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 56, 46, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 28, 23, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 28, 23, 128)       73856     \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, 28, 23, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 28, 23, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 14, 11, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 19712)             0         \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 19712)             0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1024)              20186112  \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 20)                10260     \n",
            "=================================================================\n",
            "Total params: 21,007,604\n",
            "Trainable params: 21,007,604\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoK5Rk1vVuCG",
        "outputId": "9aa35e4b-b4c1-4b72-e61e-df59579b76eb"
      },
      "source": [
        "Model= model.fit(X_train, Y_train, validation_data=(x_test, y_test), epochs=300, batch_size=32)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "8/8 [==============================] - 21s 2s/step - loss: 3.0027 - accuracy: 0.0543 - val_loss: 2.9910 - val_accuracy: 0.0625\n",
            "Epoch 2/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 2.9772 - accuracy: 0.0425 - val_loss: 2.9885 - val_accuracy: 0.0500\n",
            "Epoch 3/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 2.9735 - accuracy: 0.0453 - val_loss: 2.9861 - val_accuracy: 0.0625\n",
            "Epoch 4/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 2.9596 - accuracy: 0.0674 - val_loss: 2.9795 - val_accuracy: 0.1000\n",
            "Epoch 5/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 2.9517 - accuracy: 0.0588 - val_loss: 2.9708 - val_accuracy: 0.0500\n",
            "Epoch 6/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 2.9137 - accuracy: 0.1018 - val_loss: 2.9520 - val_accuracy: 0.1312\n",
            "Epoch 7/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 2.8915 - accuracy: 0.1321 - val_loss: 2.9094 - val_accuracy: 0.0875\n",
            "Epoch 8/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 2.7877 - accuracy: 0.1535 - val_loss: 2.8490 - val_accuracy: 0.1875\n",
            "Epoch 9/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 2.7190 - accuracy: 0.1139 - val_loss: 2.7754 - val_accuracy: 0.2313\n",
            "Epoch 10/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 2.6331 - accuracy: 0.2003 - val_loss: 2.7126 - val_accuracy: 0.5250\n",
            "Epoch 11/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 2.3423 - accuracy: 0.3033 - val_loss: 2.4341 - val_accuracy: 0.3938\n",
            "Epoch 12/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 2.0967 - accuracy: 0.3667 - val_loss: 2.2490 - val_accuracy: 0.7688\n",
            "Epoch 13/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 1.8324 - accuracy: 0.3963 - val_loss: 2.0433 - val_accuracy: 0.7250\n",
            "Epoch 14/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 1.4514 - accuracy: 0.5379 - val_loss: 1.6729 - val_accuracy: 0.7875\n",
            "Epoch 15/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 1.2817 - accuracy: 0.5820 - val_loss: 1.5659 - val_accuracy: 0.7688\n",
            "Epoch 16/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 1.0369 - accuracy: 0.6402 - val_loss: 1.1213 - val_accuracy: 0.8938\n",
            "Epoch 17/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.7624 - accuracy: 0.7539 - val_loss: 0.8570 - val_accuracy: 0.8687\n",
            "Epoch 18/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.7319 - accuracy: 0.7533 - val_loss: 0.7606 - val_accuracy: 0.9125\n",
            "Epoch 19/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.3830 - accuracy: 0.8893 - val_loss: 0.6600 - val_accuracy: 0.9062\n",
            "Epoch 20/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.3252 - accuracy: 0.8880 - val_loss: 0.5942 - val_accuracy: 0.9125\n",
            "Epoch 21/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.4003 - accuracy: 0.8947 - val_loss: 0.5310 - val_accuracy: 0.9125\n",
            "Epoch 22/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.3295 - accuracy: 0.9084 - val_loss: 0.4852 - val_accuracy: 0.9250\n",
            "Epoch 23/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.1982 - accuracy: 0.9592 - val_loss: 0.4024 - val_accuracy: 0.9438\n",
            "Epoch 24/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.1316 - accuracy: 0.9654 - val_loss: 0.3793 - val_accuracy: 0.9062\n",
            "Epoch 25/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.1275 - accuracy: 0.9541 - val_loss: 0.2746 - val_accuracy: 0.9625\n",
            "Epoch 26/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.1041 - accuracy: 0.9684 - val_loss: 0.3017 - val_accuracy: 0.9500\n",
            "Epoch 27/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.1141 - accuracy: 0.9466 - val_loss: 0.2979 - val_accuracy: 0.9312\n",
            "Epoch 28/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.1408 - accuracy: 0.9727 - val_loss: 0.2988 - val_accuracy: 0.9250\n",
            "Epoch 29/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0608 - accuracy: 0.9748 - val_loss: 0.2821 - val_accuracy: 0.9125\n",
            "Epoch 30/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0761 - accuracy: 0.9769 - val_loss: 0.2684 - val_accuracy: 0.9312\n",
            "Epoch 31/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0373 - accuracy: 0.9856 - val_loss: 0.2894 - val_accuracy: 0.9250\n",
            "Epoch 32/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.1675 - accuracy: 0.9397 - val_loss: 0.2289 - val_accuracy: 0.9563\n",
            "Epoch 33/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0531 - accuracy: 0.9848 - val_loss: 0.2492 - val_accuracy: 0.9375\n",
            "Epoch 34/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0437 - accuracy: 0.9787 - val_loss: 0.2937 - val_accuracy: 0.9375\n",
            "Epoch 35/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0287 - accuracy: 0.9952 - val_loss: 0.2733 - val_accuracy: 0.9312\n",
            "Epoch 36/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0406 - accuracy: 0.9839 - val_loss: 0.2375 - val_accuracy: 0.9375\n",
            "Epoch 37/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0546 - accuracy: 0.9894 - val_loss: 0.2017 - val_accuracy: 0.9625\n",
            "Epoch 38/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0517 - accuracy: 0.9851 - val_loss: 0.2121 - val_accuracy: 0.9625\n",
            "Epoch 39/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0244 - accuracy: 0.9985 - val_loss: 0.2273 - val_accuracy: 0.9500\n",
            "Epoch 40/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0184 - accuracy: 0.9928 - val_loss: 0.2538 - val_accuracy: 0.9375\n",
            "Epoch 41/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0172 - accuracy: 0.9985 - val_loss: 0.2805 - val_accuracy: 0.9375\n",
            "Epoch 42/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0187 - accuracy: 0.9934 - val_loss: 0.2547 - val_accuracy: 0.9312\n",
            "Epoch 43/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.2455 - val_accuracy: 0.9312\n",
            "Epoch 44/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0144 - accuracy: 0.9952 - val_loss: 0.2199 - val_accuracy: 0.9312\n",
            "Epoch 45/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0154 - accuracy: 0.9906 - val_loss: 0.1819 - val_accuracy: 0.9563\n",
            "Epoch 46/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.1376 - accuracy: 0.9609 - val_loss: 0.2189 - val_accuracy: 0.9438\n",
            "Epoch 47/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0475 - accuracy: 0.9738 - val_loss: 0.2608 - val_accuracy: 0.9438\n",
            "Epoch 48/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0673 - accuracy: 0.9710 - val_loss: 0.2364 - val_accuracy: 0.9500\n",
            "Epoch 49/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0517 - accuracy: 0.9795 - val_loss: 0.2145 - val_accuracy: 0.9625\n",
            "Epoch 50/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0507 - accuracy: 0.9774 - val_loss: 0.1937 - val_accuracy: 0.9563\n",
            "Epoch 51/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0299 - accuracy: 0.9900 - val_loss: 0.1909 - val_accuracy: 0.9500\n",
            "Epoch 52/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0198 - accuracy: 0.9965 - val_loss: 0.2106 - val_accuracy: 0.9500\n",
            "Epoch 53/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0527 - accuracy: 0.9899 - val_loss: 0.2429 - val_accuracy: 0.9375\n",
            "Epoch 54/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0201 - accuracy: 0.9922 - val_loss: 0.2569 - val_accuracy: 0.9438\n",
            "Epoch 55/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0374 - accuracy: 0.9884 - val_loss: 0.3073 - val_accuracy: 0.9312\n",
            "Epoch 56/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0813 - accuracy: 0.9786 - val_loss: 0.3434 - val_accuracy: 0.9062\n",
            "Epoch 57/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0804 - accuracy: 0.9741 - val_loss: 0.2048 - val_accuracy: 0.9563\n",
            "Epoch 58/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0332 - accuracy: 0.9973 - val_loss: 0.1943 - val_accuracy: 0.9500\n",
            "Epoch 59/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0640 - accuracy: 0.9728 - val_loss: 0.1761 - val_accuracy: 0.9688\n",
            "Epoch 60/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0391 - accuracy: 0.9844 - val_loss: 0.2223 - val_accuracy: 0.9500\n",
            "Epoch 61/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0223 - accuracy: 0.9965 - val_loss: 0.2566 - val_accuracy: 0.9438\n",
            "Epoch 62/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0103 - accuracy: 0.9980 - val_loss: 0.2766 - val_accuracy: 0.9375\n",
            "Epoch 63/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0186 - accuracy: 0.9935 - val_loss: 0.2654 - val_accuracy: 0.9375\n",
            "Epoch 64/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.2451 - val_accuracy: 0.9500\n",
            "Epoch 65/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.2207 - val_accuracy: 0.9625\n",
            "Epoch 66/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0170 - accuracy: 0.9952 - val_loss: 0.2225 - val_accuracy: 0.9625\n",
            "Epoch 67/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2307 - val_accuracy: 0.9625\n",
            "Epoch 68/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2457 - val_accuracy: 0.9563\n",
            "Epoch 69/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0100 - accuracy: 0.9952 - val_loss: 0.2431 - val_accuracy: 0.9563\n",
            "Epoch 70/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0082 - accuracy: 0.9952 - val_loss: 0.2434 - val_accuracy: 0.9438\n",
            "Epoch 71/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2384 - val_accuracy: 0.9438\n",
            "Epoch 72/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2403 - val_accuracy: 0.9438\n",
            "Epoch 73/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2434 - val_accuracy: 0.9438\n",
            "Epoch 74/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0368 - accuracy: 0.9870 - val_loss: 0.2368 - val_accuracy: 0.9438\n",
            "Epoch 75/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2236 - val_accuracy: 0.9438\n",
            "Epoch 76/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2754 - val_accuracy: 0.9438\n",
            "Epoch 77/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0269 - accuracy: 0.9884 - val_loss: 0.2822 - val_accuracy: 0.9375\n",
            "Epoch 78/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0145 - accuracy: 0.9900 - val_loss: 0.2642 - val_accuracy: 0.9250\n",
            "Epoch 79/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0120 - accuracy: 0.9985 - val_loss: 0.2566 - val_accuracy: 0.9125\n",
            "Epoch 80/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0298 - accuracy: 0.9789 - val_loss: 0.2413 - val_accuracy: 0.9563\n",
            "Epoch 81/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0105 - accuracy: 0.9973 - val_loss: 0.2520 - val_accuracy: 0.9563\n",
            "Epoch 82/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2522 - val_accuracy: 0.9625\n",
            "Epoch 83/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2573 - val_accuracy: 0.9625\n",
            "Epoch 84/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0130 - accuracy: 0.9914 - val_loss: 0.2643 - val_accuracy: 0.9563\n",
            "Epoch 85/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2778 - val_accuracy: 0.9500\n",
            "Epoch 86/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.2918 - val_accuracy: 0.9500\n",
            "Epoch 87/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0158 - accuracy: 0.9825 - val_loss: 0.2351 - val_accuracy: 0.9563\n",
            "Epoch 88/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0138 - accuracy: 0.9952 - val_loss: 0.2264 - val_accuracy: 0.9438\n",
            "Epoch 89/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0151 - accuracy: 0.9971 - val_loss: 0.2195 - val_accuracy: 0.9500\n",
            "Epoch 90/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2196 - val_accuracy: 0.9625\n",
            "Epoch 91/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0075 - accuracy: 0.9964 - val_loss: 0.2266 - val_accuracy: 0.9625\n",
            "Epoch 92/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.2400 - val_accuracy: 0.9563\n",
            "Epoch 93/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.2526 - val_accuracy: 0.9500\n",
            "Epoch 94/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2679 - val_accuracy: 0.9438\n",
            "Epoch 95/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 9.9457e-04 - accuracy: 1.0000 - val_loss: 0.2775 - val_accuracy: 0.9375\n",
            "Epoch 96/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2810 - val_accuracy: 0.9375\n",
            "Epoch 97/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2816 - val_accuracy: 0.9375\n",
            "Epoch 98/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2900 - val_accuracy: 0.9375\n",
            "Epoch 99/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0227 - accuracy: 0.9900 - val_loss: 0.2886 - val_accuracy: 0.9250\n",
            "Epoch 100/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0192 - accuracy: 0.9914 - val_loss: 0.3203 - val_accuracy: 0.9312\n",
            "Epoch 101/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.3310 - val_accuracy: 0.9312\n",
            "Epoch 102/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0133 - accuracy: 0.9920 - val_loss: 0.2786 - val_accuracy: 0.9312\n",
            "Epoch 103/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 4.1420e-04 - accuracy: 1.0000 - val_loss: 0.2622 - val_accuracy: 0.9375\n",
            "Epoch 104/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2566 - val_accuracy: 0.9500\n",
            "Epoch 105/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.2642 - val_accuracy: 0.9563\n",
            "Epoch 106/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2628 - val_accuracy: 0.9625\n",
            "Epoch 107/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2597 - val_accuracy: 0.9563\n",
            "Epoch 108/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0039 - accuracy: 0.9980 - val_loss: 0.2636 - val_accuracy: 0.9625\n",
            "Epoch 109/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 8.0313e-04 - accuracy: 1.0000 - val_loss: 0.2645 - val_accuracy: 0.9563\n",
            "Epoch 110/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2701 - val_accuracy: 0.9563\n",
            "Epoch 111/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 5.0551e-04 - accuracy: 1.0000 - val_loss: 0.2714 - val_accuracy: 0.9500\n",
            "Epoch 112/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 6.5657e-04 - accuracy: 1.0000 - val_loss: 0.2713 - val_accuracy: 0.9500\n",
            "Epoch 113/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2734 - val_accuracy: 0.9500\n",
            "Epoch 114/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0057 - accuracy: 0.9980 - val_loss: 0.2564 - val_accuracy: 0.9563\n",
            "Epoch 115/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.2472 - val_accuracy: 0.9563\n",
            "Epoch 116/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2525 - val_accuracy: 0.9500\n",
            "Epoch 117/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0050 - accuracy: 0.9964 - val_loss: 0.2936 - val_accuracy: 0.9375\n",
            "Epoch 118/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3520 - val_accuracy: 0.9187\n",
            "Epoch 119/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3787 - val_accuracy: 0.9187\n",
            "Epoch 120/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3738 - val_accuracy: 0.9187\n",
            "Epoch 121/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 4.4528e-04 - accuracy: 1.0000 - val_loss: 0.3663 - val_accuracy: 0.9187\n",
            "Epoch 122/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3473 - val_accuracy: 0.9250\n",
            "Epoch 123/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3329 - val_accuracy: 0.9250\n",
            "Epoch 124/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 3.8038e-04 - accuracy: 1.0000 - val_loss: 0.3212 - val_accuracy: 0.9312\n",
            "Epoch 125/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2908 - val_accuracy: 0.9438\n",
            "Epoch 126/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 7.9814e-04 - accuracy: 1.0000 - val_loss: 0.2736 - val_accuracy: 0.9563\n",
            "Epoch 127/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 2.0341e-04 - accuracy: 1.0000 - val_loss: 0.2687 - val_accuracy: 0.9563\n",
            "Epoch 128/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 3.3670e-04 - accuracy: 1.0000 - val_loss: 0.2668 - val_accuracy: 0.9563\n",
            "Epoch 129/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 3.7827e-04 - accuracy: 1.0000 - val_loss: 0.2651 - val_accuracy: 0.9563\n",
            "Epoch 130/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 3.7734e-04 - accuracy: 1.0000 - val_loss: 0.2639 - val_accuracy: 0.9563\n",
            "Epoch 131/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 8.1976e-04 - accuracy: 1.0000 - val_loss: 0.2678 - val_accuracy: 0.9563\n",
            "Epoch 132/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 3.7096e-04 - accuracy: 1.0000 - val_loss: 0.2699 - val_accuracy: 0.9563\n",
            "Epoch 133/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 3.9886e-04 - accuracy: 1.0000 - val_loss: 0.2720 - val_accuracy: 0.9563\n",
            "Epoch 134/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 3.4593e-04 - accuracy: 1.0000 - val_loss: 0.2755 - val_accuracy: 0.9563\n",
            "Epoch 135/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 5.3540e-04 - accuracy: 1.0000 - val_loss: 0.2946 - val_accuracy: 0.9563\n",
            "Epoch 136/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0071 - accuracy: 0.9952 - val_loss: 0.2968 - val_accuracy: 0.9438\n",
            "Epoch 137/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0202 - accuracy: 0.9900 - val_loss: 0.3175 - val_accuracy: 0.9375\n",
            "Epoch 138/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.3222 - val_accuracy: 0.9375\n",
            "Epoch 139/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 9.4088e-04 - accuracy: 1.0000 - val_loss: 0.3326 - val_accuracy: 0.9375\n",
            "Epoch 140/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 3.9878e-04 - accuracy: 1.0000 - val_loss: 0.3388 - val_accuracy: 0.9375\n",
            "Epoch 141/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0062 - accuracy: 0.9964 - val_loss: 0.3335 - val_accuracy: 0.9375\n",
            "Epoch 142/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.3076 - val_accuracy: 0.9375\n",
            "Epoch 143/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3040 - val_accuracy: 0.9500\n",
            "Epoch 144/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3183 - val_accuracy: 0.9438\n",
            "Epoch 145/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0036 - accuracy: 0.9973 - val_loss: 0.3669 - val_accuracy: 0.9312\n",
            "Epoch 146/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0250 - accuracy: 0.9952 - val_loss: 0.3739 - val_accuracy: 0.9250\n",
            "Epoch 147/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0041 - accuracy: 0.9980 - val_loss: 0.3327 - val_accuracy: 0.9375\n",
            "Epoch 148/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0081 - accuracy: 0.9965 - val_loss: 0.2886 - val_accuracy: 0.9438\n",
            "Epoch 149/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 4.9228e-04 - accuracy: 1.0000 - val_loss: 0.2522 - val_accuracy: 0.9438\n",
            "Epoch 150/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2464 - val_accuracy: 0.9438\n",
            "Epoch 151/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0074 - accuracy: 0.9952 - val_loss: 0.2771 - val_accuracy: 0.9438\n",
            "Epoch 152/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0185 - accuracy: 0.9952 - val_loss: 0.2824 - val_accuracy: 0.9625\n",
            "Epoch 153/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0137 - accuracy: 0.9965 - val_loss: 0.2765 - val_accuracy: 0.9625\n",
            "Epoch 154/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.2632 - val_accuracy: 0.9500\n",
            "Epoch 155/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2543 - val_accuracy: 0.9625\n",
            "Epoch 156/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0070 - accuracy: 0.9959 - val_loss: 0.2510 - val_accuracy: 0.9500\n",
            "Epoch 157/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0026 - accuracy: 0.9980 - val_loss: 0.2678 - val_accuracy: 0.9375\n",
            "Epoch 158/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2789 - val_accuracy: 0.9375\n",
            "Epoch 159/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0533 - accuracy: 0.9860 - val_loss: 0.2441 - val_accuracy: 0.9375\n",
            "Epoch 160/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0143 - accuracy: 0.9973 - val_loss: 0.2602 - val_accuracy: 0.9312\n",
            "Epoch 161/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.3730 - val_accuracy: 0.8813\n",
            "Epoch 162/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0373 - accuracy: 0.9878 - val_loss: 0.2480 - val_accuracy: 0.9563\n",
            "Epoch 163/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0189 - accuracy: 0.9928 - val_loss: 0.3104 - val_accuracy: 0.9250\n",
            "Epoch 164/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0439 - accuracy: 0.9798 - val_loss: 0.2836 - val_accuracy: 0.9312\n",
            "Epoch 165/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0479 - accuracy: 0.9673 - val_loss: 0.2803 - val_accuracy: 0.9438\n",
            "Epoch 166/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0349 - accuracy: 0.9899 - val_loss: 0.3479 - val_accuracy: 0.9250\n",
            "Epoch 167/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0216 - accuracy: 0.9880 - val_loss: 0.3036 - val_accuracy: 0.9375\n",
            "Epoch 168/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.3850 - val_accuracy: 0.9062\n",
            "Epoch 169/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0245 - accuracy: 0.9928 - val_loss: 0.4209 - val_accuracy: 0.9250\n",
            "Epoch 170/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.4330 - val_accuracy: 0.9187\n",
            "Epoch 171/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0190 - accuracy: 0.9980 - val_loss: 0.3781 - val_accuracy: 0.9062\n",
            "Epoch 172/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0253 - accuracy: 0.9900 - val_loss: 0.2819 - val_accuracy: 0.9563\n",
            "Epoch 173/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.2359 - val_accuracy: 0.9625\n",
            "Epoch 174/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0203 - accuracy: 0.9880 - val_loss: 0.2573 - val_accuracy: 0.9625\n",
            "Epoch 175/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2557 - val_accuracy: 0.9625\n",
            "Epoch 176/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2600 - val_accuracy: 0.9563\n",
            "Epoch 177/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0104 - accuracy: 0.9928 - val_loss: 0.2771 - val_accuracy: 0.9625\n",
            "Epoch 178/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0075 - accuracy: 0.9980 - val_loss: 0.3128 - val_accuracy: 0.9438\n",
            "Epoch 179/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0184 - accuracy: 0.9900 - val_loss: 0.2974 - val_accuracy: 0.9500\n",
            "Epoch 180/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0145 - accuracy: 0.9952 - val_loss: 0.3000 - val_accuracy: 0.9375\n",
            "Epoch 181/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.3043 - val_accuracy: 0.9312\n",
            "Epoch 182/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.2912 - val_accuracy: 0.9375\n",
            "Epoch 183/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2863 - val_accuracy: 0.9375\n",
            "Epoch 184/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0075 - accuracy: 0.9980 - val_loss: 0.2891 - val_accuracy: 0.9500\n",
            "Epoch 185/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 1.1259e-04 - accuracy: 1.0000 - val_loss: 0.2920 - val_accuracy: 0.9500\n",
            "Epoch 186/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3015 - val_accuracy: 0.9500\n",
            "Epoch 187/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 5.8335e-04 - accuracy: 1.0000 - val_loss: 0.3103 - val_accuracy: 0.9500\n",
            "Epoch 188/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0033 - accuracy: 0.9973 - val_loss: 0.3251 - val_accuracy: 0.9438\n",
            "Epoch 189/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 2.6375e-04 - accuracy: 1.0000 - val_loss: 0.3425 - val_accuracy: 0.9250\n",
            "Epoch 190/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.3591 - val_accuracy: 0.9250\n",
            "Epoch 191/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.3484 - val_accuracy: 0.9438\n",
            "Epoch 192/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 1.6643e-04 - accuracy: 1.0000 - val_loss: 0.3156 - val_accuracy: 0.9625\n",
            "Epoch 193/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0313 - accuracy: 0.9928 - val_loss: 0.2813 - val_accuracy: 0.9688\n",
            "Epoch 194/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0357 - accuracy: 0.9886 - val_loss: 0.3397 - val_accuracy: 0.9438\n",
            "Epoch 195/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0030 - accuracy: 0.9973 - val_loss: 0.3580 - val_accuracy: 0.9438\n",
            "Epoch 196/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0103 - accuracy: 0.9900 - val_loss: 0.3564 - val_accuracy: 0.9375\n",
            "Epoch 197/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3526 - val_accuracy: 0.9438\n",
            "Epoch 198/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0065 - accuracy: 0.9964 - val_loss: 0.3699 - val_accuracy: 0.9250\n",
            "Epoch 199/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0175 - accuracy: 0.9920 - val_loss: 0.4109 - val_accuracy: 0.9187\n",
            "Epoch 200/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.3980 - val_accuracy: 0.9125\n",
            "Epoch 201/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0256 - accuracy: 0.9916 - val_loss: 0.3882 - val_accuracy: 0.9312\n",
            "Epoch 202/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0100 - accuracy: 0.9980 - val_loss: 0.3889 - val_accuracy: 0.9312\n",
            "Epoch 203/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3694 - val_accuracy: 0.9250\n",
            "Epoch 204/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.3570 - val_accuracy: 0.9375\n",
            "Epoch 205/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 5.8836e-04 - accuracy: 1.0000 - val_loss: 0.3541 - val_accuracy: 0.9375\n",
            "Epoch 206/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0158 - accuracy: 0.9900 - val_loss: 0.3130 - val_accuracy: 0.9625\n",
            "Epoch 207/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.3094 - val_accuracy: 0.9625\n",
            "Epoch 208/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3126 - val_accuracy: 0.9625\n",
            "Epoch 209/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 5.0333e-04 - accuracy: 1.0000 - val_loss: 0.3131 - val_accuracy: 0.9625\n",
            "Epoch 210/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 4.1018e-04 - accuracy: 1.0000 - val_loss: 0.3079 - val_accuracy: 0.9625\n",
            "Epoch 211/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0128 - accuracy: 0.9900 - val_loss: 0.2977 - val_accuracy: 0.9625\n",
            "Epoch 212/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 1.9067e-04 - accuracy: 1.0000 - val_loss: 0.3000 - val_accuracy: 0.9625\n",
            "Epoch 213/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0116 - accuracy: 0.9935 - val_loss: 0.2959 - val_accuracy: 0.9625\n",
            "Epoch 214/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0119 - accuracy: 0.9964 - val_loss: 0.3014 - val_accuracy: 0.9625\n",
            "Epoch 215/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.3393 - val_accuracy: 0.9312\n",
            "Epoch 216/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.3538 - val_accuracy: 0.9375\n",
            "Epoch 217/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0752 - accuracy: 0.9900 - val_loss: 0.3161 - val_accuracy: 0.9563\n",
            "Epoch 218/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3071 - val_accuracy: 0.9563\n",
            "Epoch 219/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0050 - accuracy: 0.9964 - val_loss: 0.3074 - val_accuracy: 0.9563\n",
            "Epoch 220/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 4.1889e-04 - accuracy: 1.0000 - val_loss: 0.3124 - val_accuracy: 0.9563\n",
            "Epoch 221/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 7.7993e-04 - accuracy: 1.0000 - val_loss: 0.3159 - val_accuracy: 0.9563\n",
            "Epoch 222/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3141 - val_accuracy: 0.9625\n",
            "Epoch 223/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0063 - accuracy: 0.9935 - val_loss: 0.3022 - val_accuracy: 0.9563\n",
            "Epoch 224/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 9.0839e-04 - accuracy: 1.0000 - val_loss: 0.2989 - val_accuracy: 0.9563\n",
            "Epoch 225/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 1.9551e-04 - accuracy: 1.0000 - val_loss: 0.2990 - val_accuracy: 0.9563\n",
            "Epoch 226/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2983 - val_accuracy: 0.9625\n",
            "Epoch 227/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 5.9961e-04 - accuracy: 1.0000 - val_loss: 0.2983 - val_accuracy: 0.9625\n",
            "Epoch 228/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 3.8175e-04 - accuracy: 1.0000 - val_loss: 0.3024 - val_accuracy: 0.9625\n",
            "Epoch 229/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 1.6032e-04 - accuracy: 1.0000 - val_loss: 0.3059 - val_accuracy: 0.9625\n",
            "Epoch 230/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 1.1623e-04 - accuracy: 1.0000 - val_loss: 0.3120 - val_accuracy: 0.9625\n",
            "Epoch 231/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 2.0076e-04 - accuracy: 1.0000 - val_loss: 0.3160 - val_accuracy: 0.9625\n",
            "Epoch 232/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 1.8523e-04 - accuracy: 1.0000 - val_loss: 0.3163 - val_accuracy: 0.9625\n",
            "Epoch 233/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 3.9384e-04 - accuracy: 1.0000 - val_loss: 0.3169 - val_accuracy: 0.9625\n",
            "Epoch 234/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 1.6509e-04 - accuracy: 1.0000 - val_loss: 0.3173 - val_accuracy: 0.9625\n",
            "Epoch 235/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 6.4382e-04 - accuracy: 1.0000 - val_loss: 0.3202 - val_accuracy: 0.9625\n",
            "Epoch 236/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 6.0954e-04 - accuracy: 1.0000 - val_loss: 0.3297 - val_accuracy: 0.9625\n",
            "Epoch 237/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 3.6283e-05 - accuracy: 1.0000 - val_loss: 0.3347 - val_accuracy: 0.9625\n",
            "Epoch 238/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 7.9262e-05 - accuracy: 1.0000 - val_loss: 0.3369 - val_accuracy: 0.9625\n",
            "Epoch 239/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 3.9589e-04 - accuracy: 1.0000 - val_loss: 0.3401 - val_accuracy: 0.9563\n",
            "Epoch 240/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 2.8717e-04 - accuracy: 1.0000 - val_loss: 0.3420 - val_accuracy: 0.9563\n",
            "Epoch 241/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 1.5830e-04 - accuracy: 1.0000 - val_loss: 0.3438 - val_accuracy: 0.9563\n",
            "Epoch 242/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 1.9068e-04 - accuracy: 1.0000 - val_loss: 0.3443 - val_accuracy: 0.9563\n",
            "Epoch 243/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 2.7100e-04 - accuracy: 1.0000 - val_loss: 0.3439 - val_accuracy: 0.9563\n",
            "Epoch 244/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 1.1656e-04 - accuracy: 1.0000 - val_loss: 0.3424 - val_accuracy: 0.9563\n",
            "Epoch 245/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3399 - val_accuracy: 0.9625\n",
            "Epoch 246/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 1.7789e-04 - accuracy: 1.0000 - val_loss: 0.3397 - val_accuracy: 0.9625\n",
            "Epoch 247/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 3.5819e-05 - accuracy: 1.0000 - val_loss: 0.3398 - val_accuracy: 0.9625\n",
            "Epoch 248/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 3.4917e-05 - accuracy: 1.0000 - val_loss: 0.3399 - val_accuracy: 0.9625\n",
            "Epoch 249/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 9.5498e-04 - accuracy: 1.0000 - val_loss: 0.3399 - val_accuracy: 0.9625\n",
            "Epoch 250/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 5.9470e-05 - accuracy: 1.0000 - val_loss: 0.3394 - val_accuracy: 0.9625\n",
            "Epoch 251/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 1.5247e-04 - accuracy: 1.0000 - val_loss: 0.3394 - val_accuracy: 0.9625\n",
            "Epoch 252/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 1.0103e-04 - accuracy: 1.0000 - val_loss: 0.3389 - val_accuracy: 0.9625\n",
            "Epoch 253/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 8.1301e-05 - accuracy: 1.0000 - val_loss: 0.3379 - val_accuracy: 0.9625\n",
            "Epoch 254/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 1.8168e-04 - accuracy: 1.0000 - val_loss: 0.3383 - val_accuracy: 0.9625\n",
            "Epoch 255/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 1.6243e-04 - accuracy: 1.0000 - val_loss: 0.3378 - val_accuracy: 0.9625\n",
            "Epoch 256/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 9.1786e-04 - accuracy: 1.0000 - val_loss: 0.3430 - val_accuracy: 0.9625\n",
            "Epoch 257/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 3.5790e-05 - accuracy: 1.0000 - val_loss: 0.3467 - val_accuracy: 0.9625\n",
            "Epoch 258/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 5.9966e-05 - accuracy: 1.0000 - val_loss: 0.3483 - val_accuracy: 0.9625\n",
            "Epoch 259/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 5.5700e-05 - accuracy: 1.0000 - val_loss: 0.3491 - val_accuracy: 0.9625\n",
            "Epoch 260/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 1.4100e-04 - accuracy: 1.0000 - val_loss: 0.3495 - val_accuracy: 0.9625\n",
            "Epoch 261/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 2.3293e-04 - accuracy: 1.0000 - val_loss: 0.3514 - val_accuracy: 0.9625\n",
            "Epoch 262/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 3.5532e-05 - accuracy: 1.0000 - val_loss: 0.3532 - val_accuracy: 0.9625\n",
            "Epoch 263/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 2.0125e-05 - accuracy: 1.0000 - val_loss: 0.3539 - val_accuracy: 0.9625\n",
            "Epoch 264/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 1.0423e-04 - accuracy: 1.0000 - val_loss: 0.3546 - val_accuracy: 0.9625\n",
            "Epoch 265/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 5.6271e-05 - accuracy: 1.0000 - val_loss: 0.3564 - val_accuracy: 0.9625\n",
            "Epoch 266/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 3.2539e-04 - accuracy: 1.0000 - val_loss: 0.3571 - val_accuracy: 0.9625\n",
            "Epoch 267/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 7.8988e-05 - accuracy: 1.0000 - val_loss: 0.3579 - val_accuracy: 0.9625\n",
            "Epoch 268/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 5.9280e-06 - accuracy: 1.0000 - val_loss: 0.3585 - val_accuracy: 0.9625\n",
            "Epoch 269/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 2.9036e-04 - accuracy: 1.0000 - val_loss: 0.3567 - val_accuracy: 0.9625\n",
            "Epoch 270/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 2.2687e-05 - accuracy: 1.0000 - val_loss: 0.3550 - val_accuracy: 0.9625\n",
            "Epoch 271/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 9.4673e-05 - accuracy: 1.0000 - val_loss: 0.3537 - val_accuracy: 0.9625\n",
            "Epoch 272/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 9.4609e-05 - accuracy: 1.0000 - val_loss: 0.3522 - val_accuracy: 0.9625\n",
            "Epoch 273/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 9.6108e-05 - accuracy: 1.0000 - val_loss: 0.3509 - val_accuracy: 0.9625\n",
            "Epoch 274/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 7.8933e-04 - accuracy: 1.0000 - val_loss: 0.3619 - val_accuracy: 0.9625\n",
            "Epoch 275/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 9.5781e-04 - accuracy: 1.0000 - val_loss: 0.3659 - val_accuracy: 0.9563\n",
            "Epoch 276/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 3.1931e-05 - accuracy: 1.0000 - val_loss: 0.3664 - val_accuracy: 0.9563\n",
            "Epoch 277/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.4052 - val_accuracy: 0.9375\n",
            "Epoch 278/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4035 - val_accuracy: 0.9375\n",
            "Epoch 279/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0073 - accuracy: 0.9935 - val_loss: 0.3260 - val_accuracy: 0.9563\n",
            "Epoch 280/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 6.9308e-05 - accuracy: 1.0000 - val_loss: 0.3194 - val_accuracy: 0.9438\n",
            "Epoch 281/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.2995 - val_accuracy: 0.9625\n",
            "Epoch 282/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 6.9526e-04 - accuracy: 1.0000 - val_loss: 0.2981 - val_accuracy: 0.9625\n",
            "Epoch 283/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 1.7808e-04 - accuracy: 1.0000 - val_loss: 0.3080 - val_accuracy: 0.9625\n",
            "Epoch 284/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 1.7576e-04 - accuracy: 1.0000 - val_loss: 0.3146 - val_accuracy: 0.9625\n",
            "Epoch 285/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 8.5149e-04 - accuracy: 1.0000 - val_loss: 0.3156 - val_accuracy: 0.9625\n",
            "Epoch 286/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 5.7175e-05 - accuracy: 1.0000 - val_loss: 0.3175 - val_accuracy: 0.9625\n",
            "Epoch 287/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0013 - accuracy: 0.9985 - val_loss: 0.3175 - val_accuracy: 0.9625\n",
            "Epoch 288/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 2.1376e-05 - accuracy: 1.0000 - val_loss: 0.3150 - val_accuracy: 0.9625\n",
            "Epoch 289/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 3.2453e-04 - accuracy: 1.0000 - val_loss: 0.3167 - val_accuracy: 0.9625\n",
            "Epoch 290/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3341 - val_accuracy: 0.9625\n",
            "Epoch 291/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 3.1329e-05 - accuracy: 1.0000 - val_loss: 0.3445 - val_accuracy: 0.9563\n",
            "Epoch 292/300\n",
            "8/8 [==============================] - 18s 2s/step - loss: 3.8256e-04 - accuracy: 1.0000 - val_loss: 0.3479 - val_accuracy: 0.9563\n",
            "Epoch 293/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 1.4801e-05 - accuracy: 1.0000 - val_loss: 0.3495 - val_accuracy: 0.9563\n",
            "Epoch 294/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 1.1481e-05 - accuracy: 1.0000 - val_loss: 0.3502 - val_accuracy: 0.9563\n",
            "Epoch 295/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 5.2657e-05 - accuracy: 1.0000 - val_loss: 0.3508 - val_accuracy: 0.9563\n",
            "Epoch 296/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 6.3861e-04 - accuracy: 1.0000 - val_loss: 0.3529 - val_accuracy: 0.9625\n",
            "Epoch 297/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 1.0473e-05 - accuracy: 1.0000 - val_loss: 0.3593 - val_accuracy: 0.9625\n",
            "Epoch 298/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 3.4606e-05 - accuracy: 1.0000 - val_loss: 0.3638 - val_accuracy: 0.9625\n",
            "Epoch 299/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 1.3336e-05 - accuracy: 1.0000 - val_loss: 0.3659 - val_accuracy: 0.9625\n",
            "Epoch 300/300\n",
            "8/8 [==============================] - 19s 2s/step - loss: 3.8967e-05 - accuracy: 1.0000 - val_loss: 0.3678 - val_accuracy: 0.9625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3HWcF3dZCz2",
        "outputId": "3e760088-c99c-40b8-d3fc-89e67fb6302b"
      },
      "source": [
        "\n",
        "Scores = model.evaluate( x_test, y_test, verbose=0)\n",
        "\n",
        "print(\"Accuracy: %.2f%%\" % (Scores[1]*100))\n",
        "#print('Loss Value: '.format  Scores[0])\n",
        "\n",
        "print('Loss Value: {}'.format(np.around(Scores[0],2)))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 96.25%\n",
            "Loss Value: 0.37\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5y9KZ7YGowp2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}